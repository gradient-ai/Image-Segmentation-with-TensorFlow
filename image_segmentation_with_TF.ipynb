{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "gradient": {
     "editing": false
    },
    "id": "rCSP-dbMw88x"
   },
   "source": [
    "# Image Segmentation with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "gradient": {
     "editing": false
    },
    "id": "sMP7mglMuGT2"
   },
   "source": [
    "This tutorial will walk you through image segmentation using a modified [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) on the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) (created by Parkhi *et al*). \n",
    "\n",
    "Image segmentation involves training a neural network to output a pixel-wise mask of an image. Each pixel is given a label which falls into one of three categories: \n",
    "\n",
    "*   Class 1 : Pixel belonging to the pet.\n",
    "*   Class 2 : Pixel bordering the pet.\n",
    "*   Class 3 : Surrounding pixel.\n",
    "\n",
    "The Oxford-IIIT Pet Dataset consists of images, their corresponding labels, and pixel-wise masks.\n",
    "\n",
    "Image segmentation has many applications, such as for medical imaging, self-driving cars and satellite imaging.\n",
    "\n",
    "This was adapted from a TensorFlow tutorial by the TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git\n",
    "!pip install --upgrade tensorflow keras numpy pandas sklearn pillow\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "g87--n2AtyO_"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "This dataset is already included in the TensorFlow datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "40ITeStwDwZb"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('oxford_iiit_pet:3.2.0', with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJcVdj_U4vzf"
   },
   "source": [
    "Here we define the functions used to preprocess and load the data. The images will be flipped and normalized to a range of [0,1]. For convenience, the pixel labels are changed from {1, 2, 3} to {0, 1, 2} by subtracting 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "FD60EbcAQqov"
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask -= 1\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "2NPlCnBXQwb1"
   },
   "outputs": [],
   "source": [
    "def load_image_train(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "Zf0S67hJRp3D"
   },
   "outputs": [],
   "source": [
    "def load_image_test(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65-qHTjX5VZh"
   },
   "source": [
    "## Define train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "yHwj2-8SaQli"
   },
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "39fYScNz9lmo"
   },
   "outputs": [],
   "source": [
    "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = dataset['test'].map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "DeFwFDN6EVoI"
   },
   "outputs": [],
   "source": [
    "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xa3gMAE_9qNa"
   },
   "source": [
    "Let's take a look at an image example and its correponding mask from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "3N2RPAAW9q4W"
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "a6u_Rblkteqb"
   },
   "outputs": [],
   "source": [
    "for image, mask in train.take(1):\n",
    "  sample_image, sample_mask = image, mask\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAOe93FRMk3w"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "The model being used here is a modified U-Net, which consists of an encoder (downsampler) and decoder (upsampler). The pretrained MobileNetV2 model is used as the encoder, and the decoder will be the upsample block already implemented in TensorFlow Examples in the [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). \n",
    "\n",
    "Three channels are output because there are three possible labels for each pixel (belonging to the pet, bordering the pet, or a surrounding pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "liCeLH0ctjq7"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPw8Lzra5_T9"
   },
   "source": [
    "The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "p0ZbfywEbZpJ"
   },
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "45HByxpVtrPF"
   },
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "\n",
    "  # This is the last layer of the model\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2,\n",
    "      padding='same', activation='softmax')  #64x64 -> 128x128\n",
    "\n",
    "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0DGH_4T0VYn"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Here we're using sparse categorical crossentropy for the loss, simply because it's the recommended loss for a scenario such as multi-class prediction. The network here is trying to assign each pixel a label, and each channel is trying to learn to predict a class. Using the output of the network, the label assigned to each pixel is the channel with the highest value. This is what the create_mask function is doing.\n",
    "\n",
    "This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "6he36HK5uKAc"
   },
   "outputs": [],
   "source": [
    "model = unet_model(OUTPUT_CHANNELS)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tc3MiEO2twLS"
   },
   "source": [
    "Let's try out the model to see what it predicts before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "UwvIKLZPtxV_"
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "YLNsrynNtx4d"
   },
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "X_1CC0T4dho3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22AyVYWQdkgk"
   },
   "source": [
    "Let's observe how the model improves while it is training. To accomplish this task, a callback function is defined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "wHrHsqijdmL6"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "StKDH_B9t4SD"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_dataset,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "P_mu0SAbt40Q"
   },
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unP3cnxo_N72"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BVXldSo-0mW"
   },
   "source": [
    "The number of epochs is small in the interest of saving time, but this can be set higher to achieve more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "ikrzoG24qwf5"
   },
   "outputs": [],
   "source": [
    "show_predictions(test_dataset, 3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segmentation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
